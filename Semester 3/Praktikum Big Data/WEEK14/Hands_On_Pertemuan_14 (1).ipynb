{"cells":[{"cell_type":"markdown","id":"e2a030e3","metadata":{"id":"e2a030e3"},"source":["# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"]},{"cell_type":"markdown","id":"099562db","metadata":{"id":"099562db"},"source":["## Objectives:\n","- Understand and implement advanced machine learning tasks using Spark MLlib.\n","- Build and evaluate models using real-world datasets.\n","- Explore techniques like feature engineering and hyperparameter tuning.\n"]},{"cell_type":"markdown","id":"77df771a","metadata":{"id":"77df771a"},"source":["## Introduction to Spark MLlib\n","Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."]},{"cell_type":"code","execution_count":null,"id":"d9ae225b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1657,"status":"ok","timestamp":1733282272671,"user":{"displayName":"Restu Wibisono","userId":"16465439055803747140"},"user_tz":-420},"id":"d9ae225b","outputId":"32b774f1-ecdf-4157-8cfc-6567efb89024"},"outputs":[],"source":["# Example: Linear Regression with Spark MLlib\n","from pyspark.sql import SparkSession\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import VectorAssembler\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n","\n","# Load sample data\n","data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n","columns = ['ID', 'Feature', 'Target']\n","df = spark.createDataFrame(data, columns)\n","\n","# Prepare data for modeling\n","assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n","df_transformed = assembler.transform(df)\n","\n","# Train a linear regression model\n","lr = LinearRegression(featuresCol='Features', labelCol='Target')\n","model = lr.fit(df_transformed)\n","\n","# Print model coefficients\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')"]},{"cell_type":"code","execution_count":null,"id":"t__Qp618rhMP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6884,"status":"ok","timestamp":1733283013490,"user":{"displayName":"Restu Wibisono","userId":"16465439055803747140"},"user_tz":-420},"id":"t__Qp618rhMP","outputId":"82c43cee-abe1-4691-9943-a5363da99908"},"outputs":[],"source":["# Practice: Logistic Regression\n","from pyspark.ml.classification import LogisticRegression\n","\n","# Inisialisasi SparkSession\n","spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n","\n","# Contoh dataset\n","data = [(1, 2.0, 3.0, 0), (2, 1.0, 5.0, 1), (3, 2.5, 4.5, 1), (4, 3.0, 6.0, 0)]\n","columns = ['ID', 'Feature1', 'Feature2', 'Label']\n","df = spark.createDataFrame(data, columns)\n","\n","# mengubah kolom feature1 dan feature2 menjadi vector\n","assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='Features')\n","df = assembler.transform(df)\n","\n","# melatih model\n","lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n","model = lr.fit(df)\n","\n","# menampilkan hasil\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')"]},{"cell_type":"code","execution_count":null,"id":"0b266267","metadata":{"id":"0b266267"},"outputs":[],"source":["# Practice: Logistic Regression\n","from pyspark.ml.classification import LogisticRegression\n","\n","# Example dataset\n","data = [(1, [2.0, 3.0], 0), (2, [1.0, 5.0], 1), (3, [2.5, 4.5], 1), (4, [3.0, 6.0], 0)]\n","columns = ['ID', 'Features', 'Label']\n","df = spark.createDataFrame(data, columns)\n","\n","# Train logistic regression model\n","lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n","model = lr.fit(df)\n","\n","# Display coefficients and summary\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')\n"]},{"cell_type":"code","execution_count":null,"id":"e7emvv7HsCtD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6072,"status":"ok","timestamp":1733283041244,"user":{"displayName":"Restu Wibisono","userId":"16465439055803747140"},"user_tz":-420},"id":"e7emvv7HsCtD","outputId":"0375ab14-58a0-458c-b8e4-f8b3eebeac98"},"outputs":[],"source":["# Practice: Logistic Regression\n","from pyspark.ml.classification import LogisticRegression\n","\n","# contoh dataset\n","data = [(1, 2.0, 3.0, 0), (2, 1.0, 5.0, 1), (3, 2.5, 4.5, 1), (4, 3.0, 6.0, 0)]\n","columns = ['ID', 'Feature1', 'Feature2', 'Label']\n","df = spark.createDataFrame(data, columns)\n","\n","# menguhab kolom feature1 dan feature2 menjadi vector\n","assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='Features')\n","df = assembler.transform(df)\n","\n","# melatih model\n","lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n","model = lr.fit(df)\n","\n","# menampilkan hasil\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')"]},{"cell_type":"code","execution_count":null,"id":"b9066e04","metadata":{"id":"b9066e04"},"outputs":[],"source":["# Practice: KMeans Clustering\n","from pyspark.ml.clustering import KMeans\n","\n","# Example dataset\n","data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n","columns = ['ID', 'Features']\n","df = spark.createDataFrame(data, columns)\n","\n","# Train KMeans clustering model\n","kmeans = KMeans(featuresCol='Features', k=2)\n","model = kmeans.fit(df)\n","\n","# Show cluster centers\n","centers = model.clusterCenters()\n","print(f'Cluster Centers: {centers}')\n"]},{"cell_type":"markdown","id":"a60a8d7e","metadata":{"id":"a60a8d7e"},"source":["## Homework\n","- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n","- Build a classification model using Spark MLlib and evaluate its performance.\n","- Explore hyperparameter tuning using cross-validation.\n"]},{"cell_type":"code","execution_count":null,"id":"d64S4hFAvFZf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85413,"status":"ok","timestamp":1733283429467,"user":{"displayName":"Restu Wibisono","userId":"16465439055803747140"},"user_tz":-420},"id":"d64S4hFAvFZf","outputId":"93880040-a98e-4650-9a67-6b0f88e70811"},"outputs":[],"source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","spark = SparkSession.builder.appName(\"Homework\").getOrCreate()\n","dataPath = \"aom.us.txt\"\n","df = spark.read.csv(dataPath, header=True, inferSchema=True)\n","df.show(5)\n","\n","df = df.withColumn(\"Target\", (df[\"Close\"] > df[\"Open\"]).cast(\"int\"))\n","df = df.select(\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Target\")\n","df = df.na.drop()\n","\n","featureCols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n","assembler = VectorAssembler(inputCols=featureCols, outputCol=\"Features\")\n","df = assembler.transform(df)\n","trainDf, testDf = df.randomSplit([0.8, 0.2], seed=42)\n","\n","lr = LogisticRegression(featuresCol=\"Features\", labelCol=\"Target\")\n","model = lr.fit(trainDf)\n","predictions = model.transform(testDf)\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"Target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Model Accuracy: {accuracy}\")\n","\n","paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 1.0]).addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]).build()\n","crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n","cvModel = crossval.fit(trainDf)\n","bestModel = cvModel.bestModel\n","predictions = bestModel.transform(testDf)\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Best Model Accuracy after Tuning: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"id":"GWWO_dcSvAXx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":614744,"status":"ok","timestamp":1733284044209,"user":{"displayName":"Restu Wibisono","userId":"16465439055803747140"},"user_tz":-420},"id":"GWWO_dcSvAXx","outputId":"18d2c874-84f7-49d1-e47f-31f07584908f"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","# Inisialisasi Spark Session\n","spark = SparkSession.builder.appName(\"COVID Analysis\").getOrCreate()\n","\n","# Baca dataset\n","dataPath = \"covid.csv\"  # Ganti dengan lokasi file Anda\n","df = spark.read.csv(dataPath, header=True, inferSchema=True)\n","df.show(5)\n","\n","# Menambahkan kolom Target (misalnya: apakah ada kasus baru 'new_confirmed')\n","df = df.withColumn(\"Target\", (df[\"new_confirmed\"] > 0).cast(\"int\"))\n","\n","# Pilih kolom yang relevan untuk analisis\n","df = df.select(\"last_available_confirmed\", \"last_available_deaths\", \"estimated_population\", \"Target\").na.drop()\n","\n","# Membuat kolom fitur\n","featureCols = [\"last_available_confirmed\", \"last_available_deaths\", \"estimated_population\"]\n","assembler = VectorAssembler(inputCols=featureCols, outputCol=\"Features\")\n","df = assembler.transform(df)\n","\n","# Split data menjadi train dan test\n","trainDf, testDf = df.randomSplit([0.8, 0.2], seed=42)\n","\n","# Inisialisasi Logistic Regression\n","lr = LogisticRegression(featuresCol=\"Features\", labelCol=\"Target\")\n","model = lr.fit(trainDf)\n","\n","# Evaluasi model\n","predictions = model.transform(testDf)\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"Target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Model Accuracy: {accuracy}\")\n","\n","# Tuning Hyperparameter\n","paramGrid = ParamGridBuilder() \\\n","    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n","    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n","    .build()\n","\n","crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n","cvModel = crossval.fit(trainDf)\n","\n","# Evaluasi Model Terbaik\n","bestModel = cvModel.bestModel\n","predictions = bestModel.transform(testDf)\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Best Model Accuracy after Tuning: {accuracy}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":5}
